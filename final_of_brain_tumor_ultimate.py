# -*- coding: utf-8 -*-
"""Final_of_brain_tumor_ultimate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l7XpuNZanAx4ex4yykV8QFvH98wOs65v
"""

from google.colab import drive
drive.mount('/content/drive/')

"""**Adding The libraries**"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
import tensorflow_hub as hub
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from tensorflow.keras.applications import EfficientNetB2
from tensorflow.keras import layers, models
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization
from tensorflow.keras.models import Model
from keras.optimizers import Adam, RMSprop
import os
import seaborn

"""**Loading the datasets**"""

drt = "/content/drive/MyDrive/Datasets/Brain_Tumor_MRI/Training"
TRAINING_DATA_DIR = str(drt)
shape = 160
IMAGE_SHAPE = (shape, shape)
batch_size = 64

# Data augmentation
train_datagen_kwargs = dict(rescale=1/255,
                            validation_split=.20,
                            horizontal_flip = True,
                            vertical_flip = True,
                            rotation_range=180,
                            shear_range=10,
                            zoom_range = .2,
                            fill_mode = 'reflect',)

#20% of the data in training folder for the cross validationcheck
valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**train_datagen_kwargs)
valid_generator = valid_datagen.flow_from_directory(
    TRAINING_DATA_DIR,
    subset="validation",
    batch_size=batch_size,
    shuffle=True,
    target_size=IMAGE_SHAPE
)

#remaing 80% of the data in training folder for training the model
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**train_datagen_kwargs)
train_generator = train_datagen.flow_from_directory(
    TRAINING_DATA_DIR,
    subset="training",
    batch_size=batch_size,
    shuffle=True,
    target_size=IMAGE_SHAPE)

#loading the data from testing folder
test_datagen_kwargs = dict(rescale=1/255)
test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**test_datagen_kwargs)
test_generator = test_datagen.flow_from_directory(
    "/content/drive/MyDrive/Datasets/Brain_Tumor_MRI/Testing",
    color_mode="rgb",
    batch_size=batch_size,
    class_mode="categorical",
    target_size=IMAGE_SHAPE)

drt = "/content/drive/MyDrive/Datasets/Brain_Tumor_MRI/Training"
TRAINING_DATA_DIR = str(drt)
mobilenet_shape = 224
mobilenet_IMAGE_SHAPE = (mobilenet_shape, mobilenet_shape)
mobilenet_batch_size = 64

mobilenet_train_datagen_kwargs = dict(rescale=1/255,
                            validation_split=.20,
                            horizontal_flip = True,
                            vertical_flip = True,
                            rotation_range=180,
                            shear_range=10,
                            zoom_range = .2,
                            fill_mode = 'reflect',)

#20% of the data in training folder for the cross validationcheck
mobilenet_valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**mobilenet_train_datagen_kwargs)
mobilenet_valid_generator = mobilenet_valid_datagen.flow_from_directory(
    TRAINING_DATA_DIR,
    subset="validation",
    batch_size=mobilenet_batch_size,
    shuffle=True,
    target_size=mobilenet_IMAGE_SHAPE
)

#remaing 80% of the data in training folder for training the model
mobilenet_train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**mobilenet_train_datagen_kwargs)
mobilenet_train_generator = mobilenet_train_datagen.flow_from_directory(
    TRAINING_DATA_DIR,
    subset="training",
    batch_size=mobilenet_batch_size,
    shuffle=True,
    target_size=mobilenet_IMAGE_SHAPE)

#loading the data from testing folder
mobilenet_test_datagen_kwargs = dict(rescale=1/255)
mobilenet_test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**mobilenet_test_datagen_kwargs)
mobilenet_test_generator = mobilenet_test_datagen.flow_from_directory(
    "/content/drive/MyDrive/Datasets/Brain_Tumor_MRI/Testing",
    color_mode="rgb",
    batch_size=mobilenet_batch_size,
    class_mode="categorical",
    target_size=mobilenet_IMAGE_SHAPE)

"""**Checking the class names along with its indecies**"""

print(train_generator.class_indices)

"""**Loading the EfficientNetB2 model from tensorflow hub**"""

#  kernel_regularizer=tf.keras.regularizers.l2(0.01)
#  tf.keras.layers.Dense(10, activation='relu'),
#  tf.keras.layers.Dense(10, activation='softmax'),
# "https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b2/classification/2"
# "https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b2/feature_vector/2"
#  hub.KerasLayer("https://tfhub.dev/tensorflow/efficientnet/b2/feature-vector/1", trainable=False),
# "https://tfhub.dev/tensorflow/efficientnet/b3/classification/1"
# "https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1"
# "https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2"
# "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1"

our_model = tf.keras.Sequential([
  hub.KerasLayer("https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1", trainable=False),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dropout(0.30),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Dense(64, activation='relu'),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Dense(32, activation='relu'),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Dense(train_generator.num_classes, activation='softmax'),
])

our_model.build([None, 224, 224, 3])
our_model.summary()

"""**EarlyStopping Config**"""

#callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=2)
callback = tf.keras.callbacks.EarlyStopping(monitor='acc', patience=2)

"""**Configuring the model**"""

#RMSprop(learning_rate=1e-2)
our_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), loss='categorical_crossentropy', metrics=['acc'])

"""**Fitting the model along with corss validation check**"""

steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)


our_hist = our_model.fit(
    train_generator,
    epochs=50,
    callbacks=[callback],
    verbose=1,
    validation_data=valid_generator,).history


#mobilenet_

our_model_final_loss, our_model_final_accuracy = our_model.evaluate(mobilenet_valid_generator)
print("Final loss: {:.2f}".format(our_model_final_loss))
print("Final accuracy: {:.2f}%".format(our_model_final_accuracy * 100))

our_model.save('/content/drive/MyDrive/trained model/efficientnetB0_model_new_3.h5')

"""**Plotting the fiegure of training**"""

plt.figure(figsize=(8,3))
plt.subplot(121)
plt.plot(our_hist["acc"])
plt.plot(our_hist["val_acc"])
plt.title("model accuracy vs epochs")
plt.ylabel("accuracy")
plt.xlabel("epoch")
plt.legend(["train", "validation"], loc="lower right")
plt.show()

plt.subplot(122)
plt.plot(our_hist["loss"])
plt.plot(our_hist["val_loss"])
plt.title("model loss vs epochs")
plt.ylabel("loss")
plt.xlabel("epoch")
plt.legend(["train", "validation"], loc="upper right")
plt.show()

"""**Loading the MobileNetV3 model from tensorflow hub**"""

MobileNet = tf.keras.Sequential([
  hub.KerasLayer("https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5", trainable=False),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(64, activation='relu'),
  tf.keras.layers.Dropout(.25),
  tf.keras.layers.Dense(mobilenet_train_generator.num_classes, activation='softmax')
])

MobileNet.build([None, 224, 224, 3])
MobileNet.summary()

MobileNet.compile( optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['acc'])

steps_per_epoch = np.ceil(mobilenet_train_generator.samples/mobilenet_train_generator.batch_size)


MobileNet_hist = MobileNet.fit(
    mobilenet_train_generator,
    epochs=50,
    callbacks=[callback],
    verbose=1,
    validation_data=mobilenet_valid_generator,).history

MobileNet.save('/content/drive/MyDrive/trained model/MobileNetV3_model.h5')

"""**Loading the Resnetv2 model from tensorflow hub**"""

ResNet = tf.keras.Sequential([
  hub.KerasLayer("https://tfhub.dev/google/imagenet/resnet_v2_152/feature_vector/5", trainable=False),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(64, activation='relu'),
  tf.keras.layers.Dropout(.25),
  tf.keras.layers.Dense(mobilenet_train_generator.num_classes, activation='softmax')
])

ResNet.build([None, 224, 224, 3])
ResNet.summary()

ResNet.compile( optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['acc'])

steps_per_epoch = np.ceil(mobilenet_train_generator.samples/mobilenet_train_generator.batch_size)


ResNet_hist = ResNet.fit(
    mobilenet_train_generator,
    epochs=50,
    callbacks=[callback],
    verbose=1,
    validation_data=mobilenet_valid_generator,).history

ResNet.save('/content/drive/MyDrive/trained model/ResNetV2_model.h5')

"""**Loading the inceptionv1 model from tensorflow hubt**"""

inception_v1 = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/imagenet/inception_v1/feature_vector/5",
                   trainable=False),  # Can be True, see below.
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(.25),
    tf.keras.layers.Dense(mobilenet_train_generator.num_classes, activation='softmax')
])
inception_v1.build([None, 224, 224, 3])
inception_v1.summary()

inception_v1.compile( optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['acc'])

steps_per_epoch = np.ceil(mobilenet_train_generator.samples/mobilenet_train_generator.batch_size)


inception_v1_hist = inception_v1.fit(
    mobilenet_train_generator,
    epochs=50,
    callbacks=[callback],
    verbose=1,
    validation_data=mobilenet_valid_generator,).history

inception_v1.save('/content/drive/MyDrive/trained model/inceptionv1_model.h5')

"""**Loading the nasnet_mobile model from tensorflow hubt**"""

nasnet_mobile = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/5",
                   trainable=False),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(.25),
    tf.keras.layers.Dense(mobilenet_train_generator.num_classes, activation='softmax')
])
nasnet_mobile.build([None, 224, 224, 3])
nasnet_mobile.summary()

nasnet_mobile.compile( optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['acc'])

steps_per_epoch = np.ceil(mobilenet_train_generator.samples/mobilenet_train_generator.batch_size)


nasnet_mobile_hist = nasnet_mobile.fit(
    mobilenet_train_generator,
    epochs=50,
    callbacks=[callback],
    verbose=1,
    validation_data=mobilenet_valid_generator,).history

nasnet_mobile.save('/content/drive/MyDrive/trained model/nasnet_mobile_model.h5')

"""**Evaluating the model**"""

our_loaded_model = keras.models.load_model('/content/drive/MyDrive/trained model/efficientnetB0_model_new_3.keras', custom_objects={'KerasLayer':hub.KerasLayer})

MobileNet_loaded_model = keras.models.load_model("/content/drive/MyDrive/trained model/MobileNetV3_model.h5", compile=True , custom_objects={'KerasLayer':hub.KerasLayer})
ResNetV2_loaded_model = keras.models.load_model("/content/drive/MyDrive/trained model/ResNetV2_model.h5", compile=True , custom_objects={'KerasLayer':hub.KerasLayer})
inceptionv1_loaded_model = keras.models.load_model("/content/drive/MyDrive/trained model/inceptionv1_model.h5", compile=True , custom_objects={'KerasLayer':hub.KerasLayer})
nasnet_loaded_model = keras.models.load_model("/content/drive/MyDrive/trained model/nasnet_mobile_model.h5", compile=True , custom_objects={'KerasLayer':hub.KerasLayer})

our_final_loss, our_final_accuracy = our_loaded_model.evaluate(mobilenet_valid_generator)
print("Final loss: {:.2f}".format(our_final_loss))
print("Final accuracy: {:.2f}%".format(our_final_accuracy * 100))

MobileNet_final_loss, MobileNet_final_accuracy = MobileNet_loaded_model.evaluate(mobilenet_valid_generator)
print("Final loss: {:.2f}".format(MobileNet_final_loss))
print("Final accuracy: {:.2f}%".format(MobileNet_final_accuracy * 100))

ResNetV2_final_loss, ResNetV2_final_accuracy = ResNetV2_loaded_model.evaluate(mobilenet_valid_generator)
print("Final loss: {:.2f}".format(ResNetV2_final_loss))
print("Final accuracy: {:.2f}%".format(ResNetV2_final_accuracy * 100))

inceptionv1_final_loss, inceptionv1_final_accuracy = inceptionv1_loaded_model.evaluate(mobilenet_valid_generator)
print("Final loss: {:.2f}".format(inceptionv1_final_loss))
print("Final accuracy: {:.2f}%".format(inceptionv1_final_accuracy * 100))

nasnet_final_loss, nasnet_final_accuracy = nasnet_loaded_model.evaluate(mobilenet_valid_generator)
print("Final loss: {:.2f}".format(nasnet_final_loss))
print("Final accuracy: {:.2f}%".format(nasnet_final_accuracy * 100))

data = [our_final_accuracy, MobileNet_final_accuracy, ResNetV2_final_accuracy, inceptionv1_final_accuracy, nasnet_final_accuracy]
labels = ["EfficentNetB0", "MobileNetV3Large", "ResNetV2", "InceptionV1", "NasNet"]


max_index = data.index(max(data))


plt.figure(figsize=(10, 6))
plt.bar(labels, data, color=['green' if i != max_index else 'orange' for i in range(len(data))])


plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Model Accuracy Comparison')


formatted_max = f'{max(data):.2f * 100}%'
plt.text(max_index, max(data), f'Highest: {formatted_max}', ha='center', va='bottom', color='red')


plt.xticks(rotation=45)


plt.tight_layout()
plt.show()

loss = [our_final_loss, MobileNet_final_loss, ResNetV2_final_loss, inceptionv1_final_loss, nasnet_final_loss]
labels = ["EfficentNetB3", "MobileNet", "ResNetV2", "InceptionV1", "NasNet"]


min_index = loss.index(min(loss))


plt.figure(figsize=(10, 6))
plt.bar(labels, loss, color=['green' if i != min_index else 'orange' for i in range(len(loss))])


plt.xlabel('Models')
plt.ylabel('Loss')
plt.title('Model Loss Comparison')


formatted_min = f'{min(loss):.4f}'
plt.text(min_index, min(loss), f'Lowest: {formatted_min}', ha='center', va='bottom', color='red')


plt.xticks(rotation=45)


plt.tight_layout()
plt.show()

"""**Getting the images and label from a validation batch**"""

val_image_batch, val_label_batch = next(iter(valid_generator))
true_label_ids = np.argmax(val_label_batch, axis=-1)
print("Validation batch shape:", val_image_batch.shape)

"""**Getting the labels from the indecies in a validation batch**"""

dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])
dataset_labels = np.array([key.title() for key, value in dataset_labels])
print(dataset_labels)

"""**Doing predictions on the validation batch**"""

tf_model_predictions = our_loaded_model.predict(val_image_batch)
print("Prediction results shape:", tf_model_predictions.shape)

print('\n')

predicted_ids = np.argmax(tf_model_predictions, axis=-1)
predicted_labels = dataset_labels[predicted_ids]
print(predicted_labels)

"""**Plotting the validation batch with the predicted labels and images(mri)**"""

plt.figure(figsize=(15,10))
plt.subplots_adjust(hspace=1.25)
for n in range((len(predicted_labels))):
  plt.subplot(10,8,n+1)
  plt.imshow(val_image_batch[n])
  color = "green" if predicted_ids[n] == true_label_ids[n] else "red"
  plt.title(predicted_labels[n].title(), color=color)
  plt.axis('off')
_ = plt.suptitle("Model predictions (green: correct, red: incorrect)")

print('Accuracy :', 100* accuracy_score(true_label_ids, predicted_ids))

print('Precision :', 100* precision_score(true_label_ids, predicted_ids, average='weighted'))

print('Recall :', 100* recall_score(true_label_ids, predicted_ids, average='weighted'))

print('F1 score :', 100* f1_score(true_label_ids, predicted_ids, average='weighted'))

"""**Test**"""

test_image_batch, test_label_batch = next(iter(test_generator))
true_test_label_ids = np.argmax(test_label_batch, axis=-1)
print("Test batch shape:", test_image_batch.shape)

tf_test_model_predictions = our_loaded_model.predict(test_image_batch)
test_predicted_ids = np.argmax(tf_test_model_predictions, axis=-1)
test_predicted_labels = dataset_labels[test_predicted_ids]
print(test_predicted_labels)

plt.figure(figsize=(15,10))
plt.subplots_adjust(hspace=1.25)
for n in range((len(test_predicted_labels))):
  plt.subplot(10,8,n+1)
  plt.imshow(test_image_batch[n])
  color = "green" if test_predicted_ids[n] == true_test_label_ids[n] else "red"
  plt.title(test_predicted_labels[n].title(), color=color)
  plt.axis('off')
_ = plt.suptitle("Model predictions (green: correct, red: incorrect)")

"""**Confussion matrix**"""

#plotting the Actual vs Predicted matrix with seaborn plotting library
tf_model_test_predictions = our_loaded_model.predict(test_image_batch)
y_pred = tf_model_test_predictions
ypred = [np.argmax(i) for i in y_pred]
matrix = tf.math.confusion_matrix(labels=true_test_label_ids, predictions=ypred)
plt.figure(figsize=(15,7))
seaborn.heatmap(matrix,annot=True, fmt='d').set(title='Actual vs Predicted Matrix ( where Glioma: 0, Meningioma: 1, Notumor: 2, Pituitary: 3 )')
plt.xlabel('Predicted Outputs')
plt.ylabel('Truth/Input Values')